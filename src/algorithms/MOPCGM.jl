"""
SOURCE: Sabiâ€™u, J., Shah, A., StanimiroviÄ‡, P. S., Ivanov, B., & Waziri, M. Y. 
(2023). 
Modified optimal Perry conjugate gradient method for solving system of 
    monotone equations with applications. Applied Numerical Mathematics, 
    184, 431â€“445. 
    https://doi.org/10.1016/j.apnum.2022.10.016
"""
function MOPCGM(F::Function, x0::Vector{Float64},
    P::Function, Pcheck::Function,
    maxIter::Int64=2_000,
    tol::Float64=1e-11,
    Î»::Float64=0.1,
    Î·::Float64=0.9,
    Ï::Float64=0.1,
    Î¶::Float64=0.0001
)
    x = x0
    n1 = 1_000
    fx = F(x0)
    f_evals = 1
    d = -F(x0)
    iter = 0
    normfx = norm(fx)
    normd = norm(d)
    Î± = 0
    while true
        if iter > maxIter
            return normfx, iter, f_evals, x, :max_iters_reached
        end
        if normfx <= tol
            return normfx, iter, f_evals, x, :converged_with_x
        end

        for i in 1:n1
            Î± = Ï * Î·^i
            fxd = F(x + Î± * d)
            f_evals += 1
            if -dot(fxd, d) â‰¥ Î¶ * Î± * (normd)^2
                break
            end
        end

        z = x + Î± * d
        fz = F(z)
        normfz = norm(fz)
        f_evals += 1

        if Pcheck(z) && normfz <= tol
            return normfz, iter, f_evals, z, :converged_with_z
        end
        bk = dot(fz, -Î± * d) / (normfz)^2
        t = x - bk * fz
        xnew = P(t)
        s = z - x
        fxnew = F(xnew)
        f_evals += 1
        normfxnew = norm(fxnew)
        y = fxnew - fx + Î» * s

        Î¸ = dot(s, y) / norm(s)^2
        Î² = dot(y - Î¸ * s, fxnew) / dot(d, y)

        r = dot(fxnew, d) / (normfxnew)^2
        d = -(1 + Î² * r) * fxnew + Î² * d
        x = xnew
        fx = F(x)
        f_evals += 1
        normd = norm(d)
        normfx = norm(fx)
        iter += 1
    end
end

#function MOPCGM2(F::Function,P::Function, maxIter::Int64, x0::Vector{Float64}, ð›·::Float64, Î»::Float64, Î·::Float64, tol::Float64, Ï::Float64, Î¶::Float64)
#   x = x0;
#   fx = F(x0);
#    f_evals=1;
#    d = -F(x0);
#    iter = 0;
#    normfx = norm(fx);

#    while normfx > tol && iter < maxIter
#        Î± =0.000;
#        n1=1000;
#        for i in 1:n1
#            fxd=F(x + Ï * Î·^i*d);
#            f_evals +=1;
#            if -dot(fxd, d) â‰¥ Î¶ * Ï * Î·^i * (normfx)^2
#                Î± = max( Ï * Î·^i);
#                #println("Î± = ",  Ï * Î·^i)
#                break
#            end

#        end

#        if  normfx <= tol
#println("Converged at x = ", x, " with F(x) = ", fx)
#            return normfx, iter, f_evals
#            else
#                z = x + Î± * d;
#println("z = ", z)
#            fz=F(z);
#            normfz=norm(fz);
#            f_evals +=1;

#                if normfz <= tol 
#println("Converged at z = ", z, " with F(z) = ", F(z))
#                    return normfz, iter, f_evals
#                    else
#                        t = x - (dot(fz, x - z) / (normfz)^2) * fz;

#                end

#        xnew = P(t);      
#       s = xnew - x;
#       fxnew =F(xnew);
#        normfxnew = norm(fxnew);
#        f_evals +=1;
#        y = fxnew - fx + Î» * s;
#        r = dot(fx, d)/(normfxnew)^2;
#        Î¸ = ð›·* dot(s, y) / norm(s)^2;
#        Î² = dot(y - Î¸ * s, fxnew) / dot(d, y);
#        d =  -ð›·* fxnew - Î² * r * fxnew + Î² * d;
#        x = xnew;
#        fx = F(x);
#        normfx=norm(fx);
#        f_evals +=1
#        iter +=1



#        end




# println(" x = , F(x) = $fx")
#   end

#println("Maximum iterations reached. Final x = ", x, ", F(x) = ", F(x))
#    return norm(F(x)), iter, f_evals


#end

